{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3jUBN2s3j0nFRZ01idf7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoRigoni/MachineLearningPlayground/blob/master/Progetto_CrossSelling_MatteoRigoni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contesto\n",
        "\n",
        "> Problema di classificazione binaria\n",
        "\n",
        "Il cliente è una compagnia di assicurazioni che ha fornito un'assicurazione sanitaria ai suoi clienti, adesso hanno bisogno del tuo aiuto per costruire un modello predittivo in grado di prevedere se gli assicurati dell'anno passato potrebbero essere interessati ad acquistare anche un'assicurazione per il proprio veicolo.\n",
        "\n",
        "Il dataset è composto dalle seguenti proprietà:\n",
        "\n",
        "* id: id univoco dell'acquirente.\n",
        "* Gender: sesso dell'acquirente.\n",
        "* Age: età dell'acquirente.\n",
        "* Driving_License: 1 se l'utente ha la patente di guida, 0 altrimenti.\n",
        "* Region_Code: codice univoco della regione dell'acquirente.\n",
        "* Previously_Insured: 1 se l'utente ha già un veicolo assicurato, 0 altrimenti.\n",
        "* Vehicle_Age: età del veicolo\n",
        "* Vehicle_Damage: 1 se l'utente ha danneggiato il veicolo in passato, 0 altrimenti.\n",
        "* Annual_Premium: la cifra che l'utente deve pagare come premio durante l'anno.\n",
        "* Policy_Sales_Channel: codice anonimizzato del canale utilizzato per la proposta (es. per email, per telefono, di persona, ecc...)\n",
        "* Vintage: numero di giorni dalla quale l'utente è cliente dell'azienda.\n",
        "* Response: 1 se l'acquirente ha risposto positivamente alla proposta di vendita, 0 altrimenti.\n",
        "\n",
        "\n",
        "> L'obiettivo del modello è prevedere il valore di Response.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2zjQFI_fo-et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lettura del dataset\n",
        "\n",
        "Si legge il dataset, leggendo la prima colonna come indice e si valutano le classi sbilanciate tramite il comando *value_counts*\n",
        "\n",
        "Emerge che la classe \"Response\" è molto sbilanciata, quindi sono molti di più coloro che non hanno aderito alla proposta di vendita\n",
        "\n",
        "Si imposta un random_seed per i successivi calcoli in modo da avere sempre gli stessi valori"
      ],
      "metadata": {
        "id": "dFt1KL4IpiYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "RANDOM_SEED = 2\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/MatteoRigoni/MachineLearningPlayground/master/insurance_cross_sell.csv', index_col=0)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(df['Response'].value_counts())"
      ],
      "metadata": {
        "id": "WVnYzZuLplHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing del dataset\n",
        "\n",
        "Di seguito si trasformano le variabili categoriche in numeriche.\n",
        "Alcune si mappano manualmente in modo da dare un significato preciso alle categorie.\n",
        "\n",
        "Tramite *df.count()* si evince che non ci sono dati mancanti da compensare\n",
        "\n",
        "In seguito si effettua la separazione delle features dalla variabile target, droppando anche la colonna dell'id che non è significativa all'analisi\n",
        "\n",
        "Infine si genera un train_set ed un test_set, effettuando la standardizzazione dei dati"
      ],
      "metadata": {
        "id": "tDuGDDU4rEyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
        "df['Vehicle_Age'] = df['Vehicle_Age'].map({ '< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
        "df['Vehicle_Damage'] = df['Vehicle_Damage'].map({ 'Yes': 1, 'No': 0})\n",
        "\n",
        "print(df.count())\n",
        "\n",
        "x = df.drop(['Response'], axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=RANDOM_SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)"
      ],
      "metadata": {
        "id": "fvESWf74rHHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definizione di vari modelli da verificare\n",
        "\n",
        "Si generano diversi modelli, con regressione lineare, regressione polinomiale applicando diverse tecniche di bilanciamento.\n",
        "\n",
        "Si provano le seguenti opzioni:\n",
        "\n",
        "* nessuna tecnica di bilanciamento\n",
        "* SMOTE: dà maggiore importanza alla classe minotaria\n",
        "* Undersampling: riduce numero di esempi per la classe prevalente"
      ],
      "metadata": {
        "id": "XOjmjk58uVgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "x_train_poly = poly.fit_transform(x_train)\n",
        "x_test_poly = poly.fit_transform(x_test)\n",
        "\n",
        "models = {\n",
        "    \"Reg. lineare\": LogisticRegression(random_state=RANDOM_SEED),\n",
        "    \"Reg. lineare (balanced)\": LogisticRegression(random_state=RANDOM_SEED, class_weight='balanced')\n",
        "}\n",
        "\n",
        "sampling_patterns = {\n",
        "    \"No sampling\": None,\n",
        "    \"SMOTE\": SMOTE(random_state=RANDOM_SEED),\n",
        "    \"UnderSampling\": RandomUnderSampler(random_state=RANDOM_SEED)\n",
        "}"
      ],
      "metadata": {
        "id": "kDDz4oziqq7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definizione di un metodo per la valutazione delle caratteristiche del modello\n",
        "\n",
        "Si valutano:\n",
        "* roc_curve: per avere valutazione visiva del modello\n",
        "* auc: per stimare capacità del modello di predire il risultato (da 0 a 1, valore maggiore è meglio)\n",
        "* confusion_matrix: per vedere quanti falsi negativi/positivi ci sono (e viceversa)\n",
        "* class_report: PRECISION, RECALL, F1, ACCURACY\n",
        "* cross-validation: per verificare il comportamento al variare del training/test set, su un numero di 5 suddivisioni\n"
      ],
      "metadata": {
        "id": "uqaLjbIVs4Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate_model(model, x_train, y_train, x_test, y_test, name_model, threshold=0.5):\n",
        "  y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
        "  y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "  fp, tp, _ = roc_curve(y_test, y_pred_proba)\n",
        "  auc_score = auc(fp, tp)\n",
        "\n",
        "  cv_scores = cross_val_score(model, x_train, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "  return {\n",
        "      'fp': fp,\n",
        "      'tp': tp,\n",
        "      'AUC': auc_score,\n",
        "      'CrossValidationAUC': cv_scores.mean(),\n",
        "      'ConfusionMatrix': conf_matrix,\n",
        "      'ClassificationReport': class_report\n",
        "  }"
      ],
      "metadata": {
        "id": "juia8UDds7oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Addestramento e valutazione dei modelli\n",
        "Si combinano diverse tecniche per la gestione del dataset sbilanciato."
      ],
      "metadata": {
        "id": "XeTfVOoJyXUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for name_model, model in models.items():\n",
        "  for sampling_name, sampling in  sampling_patterns.items():\n",
        "    if sampling:\n",
        "      x_train_balanced, y_train_balanced = sampling.fit_resample(x_train, y_train)\n",
        "    else:\n",
        "      x_train_balanced, y_train_balanced = x_train, y_train\n",
        "\n",
        "    model.fit(x_train_balanced, y_train_balanced)\n",
        "\n",
        "    result_evaluation_model = evaluate_model(model, x_train_balanced, y_train_balanced, x_test, y_test, f\"{name_model} with {sampling_name}\")\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name_model,\n",
        "        \"Sampling\": sampling_name,\n",
        "        **result_evaluation_model\n",
        "    })"
      ],
      "metadata": {
        "id": "9lcHZs1azZEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizzazione dei risultati\n",
        "\n",
        "Si confrontano visivamente e tramite valori i risultati delle combinazioni analizzate tenendo conto delle seguenti metriche:\n",
        "\n",
        "* AUC: area sotto la curva ROC, in generale un valore più vicino a 1 indica una migliore previsione da parte del modello. Sotto lo 0.5 non è significativo\n",
        "* Cross-validation AUC: media delle AUC su diversi traning/test set, in modo da essere certi che la buona predizione dell'AUC non sia dia da un divisione \"fortunata\" del dataset\n",
        "* Confusion matrix: numero di veri positivi (TP), fasi negativi (FP), veri negativi (TN) e falsi negativi (FN):\n",
        "\n",
        "    [TN  FP]\n",
        "\n",
        "    [FN  TP]\n",
        "\n",
        "* Classification report:\n",
        "  * Precision: % di predizioni positive corrette (più alto è meglio)\n",
        "  * Recall: % di effettivi positivi predetti dal modello (più alto è meglio)\n",
        "  * F1: Parametro di valutazione che si basa sia si precision che recall (più alto è meglio)\n",
        "  * Support: Numero di istanze per classe\n",
        "  * Accuracy: % di predizioni corrette (più alto è meglio)\n",
        "  * Macro average / Wighted Average: Media aritmetica/ponderata delle metriche delle due classi (più alto è meglio)"
      ],
      "metadata": {
        "id": "Dd5LQUrK6tGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for result in results:\n",
        "    print(f\"Model: {result['Model']} with sampling: {result['Sampling']}\")\n",
        "    print(f\"AUC: {result['AUC']}\")\n",
        "    print(f\"Cross-Validation AUC: {result['CrossValidationAUC']}\")\n",
        "    print(f\"Confusion Matrix:\\n{result['ConfusionMatrix']}\")\n",
        "    print(f\"Classification Report:\\n{result['ClassificationReport']}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(result['fp'], result['tp'], label=f\"AUC = {result['AUC']:.2f}\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC Curve {result['Model']} with sampling: {result['Sampling']}\")\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "vRGG8q-L6vu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Considerazioni sui risultati\n",
        "\n",
        "> Model: Reg. lineare with sampling: No sampling\n",
        "\n",
        "AUC e cross-validation AUC simili agli altri, ma la precision sulla classe \"1\" è molto bassa con recall pari a zero, quindi si può dire che il modello fatica a identificare i casi positivi\n",
        "\n",
        "> Model: Reg. lineare with sampling: SMOTE\n",
        "\n",
        "Rispetto al caso precedente, sembra che il modello catturi in maniera più efficace i casi positivi, ma è anche aumentato il numero di falsi positivi\n",
        "\n",
        "> Model: Reg. lineare with sampling: UnderSampling\n",
        "\n",
        "Nessun risultato particolarmente diverso da quanto ottenuto con SMOTE.\n",
        "\n",
        "> Model: Reg. lineare (balanced) with sampling: No sampling\n",
        "\n",
        "Miglioramento dei parametri rispetto alla regressione non bilanciata per quanto riguarda il recall\n",
        "\n",
        "> Model: Reg. lineare (balanced) with sampling: SMOTE\n",
        "\n",
        "Rispetto al precedente c'è solo un leggerissimo miglioramento del parametro AUC\n",
        "\n",
        "> Model: Reg. lineare (balanced) with sampling: UnderSampling\n",
        "\n",
        "Come il precedente, nessun miglioramento o peggioramento rilevante\n"
      ],
      "metadata": {
        "id": "W1n9N0Z4C9qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Basandosi sul modello bilanciato con i pesi, possiamo concludere di aver ottenuto un AUC di 0.83, che indica una buona capacità predittiva, ache se non ottima.\n",
        "\n",
        "Il modello è efficace nell'identificare i casi positivi, ma restituisce anche molti falsi positivi, quindi potrebbe essere stimato che alcui clienti vogliano stipulare una assicurazione per il veicolo, ma non accadrà.\n",
        "\n",
        "L'accuratezza media complessiva del modello è del 64%.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lycMpCuQIHCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valutazione threshold ottimale\n",
        "\n",
        "Partendo dal modello migliore, quindi quello bilanciato con sampling SMOTE, si usa la funzione \"precision_recall_curve\", per trovare il valore di soglia ottimale per questo modello.\n",
        "\n",
        "Con questo valore, si rieffettua la valutazione del modello con la funzione definita in precedenza \"evaluate_model\".\n",
        "\n",
        "A parità di AUC, si ottiene una precision leggermente migliore nel predire il caso positivo, ma a scapito del recall.\n",
        "\n",
        "Questo significa che clienti potenzialmente interessate potrebbero essere omessi dalle iniziative di marketing. Considerata la differenza minima e che una proposta di acquisto non accettata non comporta danni, non si ritiene utile variare il threshold."
      ],
      "metadata": {
        "id": "QSmsJp44NqZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "import numpy as np\n",
        "\n",
        "model_final = LogisticRegression(random_state=RANDOM_SEED, class_weight='balanced')\n",
        "x_train_balanced, y_train_balanced = SMOTE(random_state=RANDOM_SEED).fit_resample(x_train, y_train)\n",
        "model_final.fit(x_train_balanced, y_train_balanced)\n",
        "\n",
        "y_pred_proba = model_final.predict_proba(x_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "name_model = f\"Regr. lineare bilanciata (con sampling SMOTE) - THRESHOLD 0.65\"\n",
        "result_evaluation_model_optimal_threshold = evaluate_model(model_final, x_train_balanced, y_train_balanced, x_test, y_test, name_model, threshold=optimal_threshold)\n",
        "\n",
        "print(name_model)\n",
        "print(f\"AUC: {result_evaluation_model_optimal_threshold['AUC']}\")\n",
        "print(f\"Cross-Validation AUC: {result_evaluation_model_optimal_threshold['CrossValidationAUC']}\")\n",
        "print(f\"Confusion Matrix:\\n{result_evaluation_model_optimal_threshold['ConfusionMatrix']}\")\n",
        "print(f\"Classification Report:\\n{result_evaluation_model_optimal_threshold['ClassificationReport']}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(result_evaluation_model_optimal_threshold['fp'], result_evaluation_model_optimal_threshold['tp'], label=f\"AUC = {result_evaluation_model_optimal_threshold['AUC']:.2f}\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(f\"ROC Curve\")\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l7xucxnvJGZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}